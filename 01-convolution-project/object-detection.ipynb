{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd965b2c",
   "metadata": {},
   "source": [
    "# SIMD-based Conv2D Object Detection\n",
    "\n",
    "In this notebook, we evaluate a custom C++ Conv2D engine (Baseline / SSE / AVX)\n",
    "\n",
    "on a simple object detection task.\n",
    "\n",
    "The pipeline includes: \n",
    "\n",
    "1. Synthetic dataset generation\n",
    "2. Optional Gaussian noise injection\n",
    "3. Edge-based object detection using Sobel (sobelx, sobely) filters\n",
    "4. Bounding box extraction\n",
    "5. IoU-based evaluation\n",
    "6. Performance benchmarking across engines "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8240a9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import time\n",
    "import shutil\n",
    "import random\n",
    "import subprocess\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ff67f3",
   "metadata": {},
   "source": [
    "## Running the C++ Conv2D Engine \n",
    "\n",
    "The function below calls the compiled C++ program using CLI arguments.\n",
    "\n",
    "It supports different engines: \n",
    "\n",
    "- baseline\n",
    "- sse\n",
    "- avx\n",
    "\n",
    "The output image is read back into Python for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc87b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conv2d(\n",
    "    engine, \n",
    "    kernel_type, \n",
    "    kernel_size,\n",
    "    input_path, \n",
    "    output_path,\n",
    "    mode=\"functional\"): \n",
    "    \n",
    "    kernel_size_str = str(kernel_size)\n",
    "    \n",
    "    cmd = [\n",
    "        \"./02-run.sh\",\n",
    "        \"--mode\", mode,\n",
    "        \"--engine\", engine,\n",
    "        \"--ktype\", kernel_type,\n",
    "        \"--ksize\", kernel_size_str,\n",
    "        \"--input\", input_path,\n",
    "        \"--output\", output_path,\n",
    "        \"--color\", \"rgb\"\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(cmd, capture_output=True, text=True)\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(\"Error running C++ program:\")\n",
    "        print(result.stderr)\n",
    "        return None \n",
    "    \n",
    "    return cv2.imread(output_path, cv2.IMREAD_GRAYSCALE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ba275b",
   "metadata": {},
   "source": [
    "## Edge-Based Object Detection Pipeline \n",
    "\n",
    "The detection pipeline consists of: \n",
    "\n",
    "1. Gaussian blur (noise reduction)\n",
    "2. Sobel X and Sobel Y filtering \n",
    "3. Gradient magnitude computation \n",
    "4. Canny edge detection \n",
    "5. Morphological dilation \n",
    "6. Connected component analysis \n",
    "7. Selecting the largest bounding box\n",
    "\n",
    "All convolutions are performed using the selected SIMD engine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e5bf87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_rectangle(engine, input_image, mode=\"functional\"):\n",
    "        \n",
    "    tmp_dir = \"tmp\"\n",
    "    os.makedirs(tmp_dir, exist_ok=True)\n",
    "    \n",
    "    blur_img = run_conv2d(engine, \"gaussian_blur\", 7, input_image, tmp_dir + \"/blur.png\")\n",
    "\n",
    "    gx_img = run_conv2d(engine, \"sobel_x\", 3, tmp_dir + \"/blur.png\", tmp_dir + \"/gx.png\")\n",
    "    gy_img = run_conv2d(engine, \"sobel_y\", 3, tmp_dir + \"/blur.png\", tmp_dir + \"/gy.png\")\n",
    " \n",
    "    gradient = np.sqrt(gx_img.astype(float) ** 2 + gy_img.astype(float) ** 2)\n",
    "    max_val = gradient.max()\n",
    "    if max_val > 0:\n",
    "        gradient = (gradient / max_val) * 255\n",
    "        \n",
    "    gradient = gradient.astype(np.uint8)\n",
    "\n",
    "    shutil.rmtree(tmp_dir)\n",
    "\n",
    "    # Edge detection\n",
    "    binary = cv2.Canny(gradient, 50, 150)\n",
    "\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    binary = cv2.dilate(binary, kernel, iterations=2)\n",
    "\n",
    "    num_labels, labels, stats, centroids = cv2.connectedComponentsWithStats(binary, connectivity=8)\n",
    "\n",
    "    best_box = None\n",
    "    best_area = 0\n",
    "\n",
    "    for i in range(1, num_labels):\n",
    "        x = stats[i, cv2.CC_STAT_LEFT]\n",
    "        y = stats[i, cv2.CC_STAT_TOP]\n",
    "        w = stats[i, cv2.CC_STAT_WIDTH]\n",
    "        h = stats[i, cv2.CC_STAT_HEIGHT]\n",
    "        area = stats[i, cv2.CC_STAT_AREA]\n",
    "\n",
    "        if area > best_area:\n",
    "            best_area = area\n",
    "            best_box = (x, y, w, h)\n",
    "\n",
    "    return best_box\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a252a1c",
   "metadata": {},
   "source": [
    "## Synthetic Dataset Generation \n",
    "\n",
    "We generate images containing:\n",
    "\n",
    "- A simple rectangle or circle \n",
    "- Random size \n",
    "- Random position \n",
    "- Random color \n",
    "\n",
    "Ground truth bounding boxes are saved in a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7887a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(output_dir=\"dataset\", num_images=300):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    ground_truths = {}\n",
    "\n",
    "    IMG_SIZE = 256\n",
    "\n",
    "    for i in range(num_images):\n",
    "        # White background\n",
    "        img = np.ones((IMG_SIZE, IMG_SIZE, 3), dtype=np.uint8) * 255\n",
    "\n",
    "        shape_type = random.choice([\"rectangle\", \"circle\"])\n",
    "\n",
    "        # Random color (avoid white)\n",
    "        color = (\n",
    "            random.randint(0, 200),\n",
    "            random.randint(0, 200),\n",
    "            random.randint(0, 200)\n",
    "        )\n",
    "\n",
    "        if shape_type == \"rectangle\":\n",
    "            w = random.randint(40, 120)\n",
    "            h = random.randint(40, 120)\n",
    "            x = random.randint(0, IMG_SIZE - w - 1)\n",
    "            y = random.randint(0, IMG_SIZE - h - 1)\n",
    "\n",
    "            cv2.rectangle(img, (x, y), (x+w, y+h), color, -1)\n",
    "\n",
    "            gt_box = (x, y, w, h)\n",
    "\n",
    "        elif shape_type == \"circle\":\n",
    "            r = random.randint(20, 60)\n",
    "            cx = random.randint(r, IMG_SIZE - r - 1)\n",
    "            cy = random.randint(r, IMG_SIZE - r - 1)\n",
    "\n",
    "            cv2.circle(img, (cx, cy), r, color, -1)\n",
    "\n",
    "            x = cx - r\n",
    "            y = cy - r\n",
    "            w = 2 * r\n",
    "            h = 2 * r\n",
    "\n",
    "            gt_box = (x, y, w, h)\n",
    "\n",
    "        filename = f\"img_{i:04d}.png\"\n",
    "        cv2.imwrite(os.path.join(output_dir, filename), img)\n",
    "\n",
    "        ground_truths[filename] = {\n",
    "            \"shape\": shape_type,\n",
    "            \"bbox\": gt_box\n",
    "        }\n",
    "\n",
    "    with open(os.path.join(output_dir, \"ground_truth.json\"), \"w\") as f:\n",
    "        json.dump(ground_truths, f, indent=4)\n",
    "\n",
    "    return ground_truths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa37f66",
   "metadata": {},
   "source": [
    "## Gaussian Noise Injection \n",
    "\n",
    "To evaluate robustness,Gaussian noise is added to the dataset.\n",
    "\n",
    "Noise parameters:\n",
    "\n",
    "- Mean = 0\n",
    "- Standard deviation = configurable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0cd4914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_gaussian_noise_to_dataset(input_dir, output_dir, mean=0, std=15):\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    shutil.copyfile(src=input_dir + \"/ground_truth.json\", dst=output_dir + \"/ground_truth.json\")\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "            input_path = os.path.join(input_dir, filename)\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "            img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            if img is None:\n",
    "                continue\n",
    "\n",
    "            # Generate noise\n",
    "            noise = np.random.normal(mean, std, img.shape)\n",
    "            noisy = img.astype(np.float32) + noise\n",
    "\n",
    "            # Clip to valid range\n",
    "            noisy = np.clip(noisy, 0, 255).astype(np.uint8)\n",
    "\n",
    "            cv2.imwrite(output_path, noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f3be47a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we generate a random synthetic dataset\n",
    "# Then add gaussian noise to it and save the output images in another dataset\n",
    "\n",
    "clean_dataset_dir = \"dataset_clean\"\n",
    "noisy_dataset_dir = \"dataset_noisy\"\n",
    "\n",
    "n_images = 100\n",
    "\n",
    "gt = generate_dataset(clean_dataset_dir, n_images)\n",
    "\n",
    "add_gaussian_noise_to_dataset(\n",
    "    clean_dataset_dir,\n",
    "    noisy_dataset_dir,\n",
    "    std=15\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5236d2b4",
   "metadata": {},
   "source": [
    "## Evaluation Metrics \n",
    "\n",
    "We evaluate detection quality using: \n",
    "\n",
    "- Accuracy \n",
    "- Precision \n",
    "- Recall \n",
    "- Mean Intersection over Union (IoU)\n",
    "\n",
    "IoU threshold for true positive classification = 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c55e9cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[0] + boxA[2], boxB[0] + boxB[2])\n",
    "    yB = min(boxA[1] + boxA[3], boxB[1] + boxB[3])\n",
    "\n",
    "    inter_w = max(0, xB - xA)\n",
    "    inter_h = max(0, yB - yA)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    areaA = boxA[2] * boxA[3]\n",
    "    areaB = boxB[2] * boxB[3]\n",
    "\n",
    "    union = areaA + areaB - inter_area\n",
    "\n",
    "    if union == 0:\n",
    "        return 0\n",
    "\n",
    "    return inter_area / union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42705387",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(dataset, engine, threshold=0.75):\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    ious = []\n",
    "\n",
    "    with open(os.path.join(dataset, \"ground_truth.json\")) as f:\n",
    "        ground_truths = json.load(f)\n",
    "        \n",
    "    start_time = time.perf_counter()\n",
    "\n",
    "    for filename, data in ground_truths.items():\n",
    "\n",
    "        path = os.path.join(dataset, filename)\n",
    "        gt_box = tuple(data[\"bbox\"]) \n",
    "\n",
    "        pred_box = detect_rectangle(engine, path)\n",
    "\n",
    "        if pred_box is None:\n",
    "            FN += 1\n",
    "            continue\n",
    "\n",
    "        iou = compute_iou(gt_box, pred_box)\n",
    "        ious.append(iou)\n",
    "\n",
    "        if iou >= threshold:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP += 1\n",
    "\n",
    "    elapsed = time.perf_counter() - start_time\n",
    "    \n",
    "    total = len(ground_truths)\n",
    "\n",
    "    accuracy  = TP / total if total > 0 else 0\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall    = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    mean_iou  = np.mean(ious) if ious else 0\n",
    "\n",
    "    return accuracy, precision, recall, mean_iou, elapsed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c02e5",
   "metadata": {},
   "source": [
    "### Single Engine Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03d8bed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.74\n",
      "Precision: 0.74\n",
      "Recall: 1.0\n",
      "Mean IoU: 0.7739399847228902\n"
     ]
    }
   ],
   "source": [
    "engine  = \"avx\"\n",
    "dataset = noisy_dataset_dir\n",
    "\n",
    "accuracy, precision, recall, mean_iou, _ = compute_metrics(dataset, engine)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"Mean IoU:\", mean_iou)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6af7814",
   "metadata": {},
   "source": [
    "## Detection Visualization\n",
    "\n",
    "Green box  → Ground Truth  \n",
    "Red box    → Prediction  \n",
    "\n",
    "This helps visually inspect detection quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c5fd86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection(image_path, gt_box=None, pred_box=None, save_path=\"debug_detection.png\"):\n",
    "\n",
    "    # Load original image \n",
    "    img = cv2.imread(image_path)\n",
    "    vis = img.copy()\n",
    "\n",
    "    # Draw GT box\n",
    "    if gt_box is not None:\n",
    "        x, y, w, h = gt_box\n",
    "        cv2.rectangle(vis, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        cv2.putText(vis, \"GT\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Draw predicted box\n",
    "    if pred_box is not None:\n",
    "        x, y, w, h = pred_box\n",
    "        cv2.rectangle(vis, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "        cv2.putText(vis, \"PRED\", (x, y - 5),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "    cv2.imwrite(save_path, vis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9db4195",
   "metadata": {},
   "source": [
    "### Visualization for n samples\n",
    "\n",
    "This function generates the visualization detection image for n samples \n",
    "\n",
    "from given dataset and save the outputs in output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce8c96e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detection_n(\n",
    "    engine,\n",
    "    dataset,\n",
    "    output_dir=\"detection\",\n",
    "    n=10):\n",
    "    \n",
    "    with open(dataset + \"/ground_truth.json\") as f:\n",
    "        ground_truths = json.load(f)\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for _, (filename, data) in zip(range(n), ground_truths.items()):\n",
    "        \n",
    "        image_path = os.path.join(dataset, filename)\n",
    "\n",
    "        gt_box = tuple(data[\"bbox\"])\n",
    "        pred_box = detect_rectangle(engine, image_path)\n",
    "        \n",
    "        output_path = output_dir + \"/\" + filename \n",
    "        \n",
    "        visualize_detection(\n",
    "            image_path,\n",
    "            gt_box=gt_box,\n",
    "            pred_box=pred_box,\n",
    "            save_path=output_path\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf3156e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine    = \"avx\"\n",
    "dataset   = noisy_dataset_dir\n",
    "n_samples = 10 \n",
    "\n",
    "visualize_detection_n(engine, dataset, n=n_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f072d3",
   "metadata": {},
   "source": [
    "## Engine Benchmark Comparison \n",
    "\n",
    "We compare:\n",
    "\n",
    "- Baseline implementation \n",
    "- SSE implementation \n",
    "- AVX implementation \n",
    "\n",
    "Metrics: \n",
    "\n",
    "- Runtime\n",
    "- Accuracy \n",
    "- Precision\n",
    "- Recall\n",
    "- Mean IoU\n",
    "\n",
    "Since all engines implement the same convolution\n",
    "\n",
    "algorithm with identical kernels and parameters, we expect: \n",
    "\n",
    "- Similar Accuracy \n",
    "- Similar Precision and Recall\n",
    "- Similar Mean IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a0f00c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== BASELINE ===\n",
      "time      : 20.4561s\n",
      "accuracy  : 0.740\n",
      "precision : 0.740\n",
      "recall    : 1.000\n",
      "mean IoU  : 0.774\n",
      "\n",
      "=== SSE ===\n",
      "time      : 20.0326s\n",
      "accuracy  : 0.740\n",
      "precision : 0.740\n",
      "recall    : 1.000\n",
      "mean IoU  : 0.774\n",
      "\n",
      "=== AVX ===\n",
      "time      : 20.0560s\n",
      "accuracy  : 0.740\n",
      "precision : 0.740\n",
      "recall    : 1.000\n",
      "mean IoU  : 0.774\n"
     ]
    }
   ],
   "source": [
    "engines = [\"baseline\", \"sse\", \"avx\"]\n",
    "dataset = noisy_dataset_dir\n",
    "\n",
    "for engine in engines:\n",
    "    acc, prec, rec, miou, t = compute_metrics(dataset, engine)\n",
    "\n",
    "    print(f\"\\n=== {engine.upper()} ===\")\n",
    "    print(f\"time      : {t:.4f}s\")\n",
    "    print(f\"accuracy  : {acc:.3f}\")\n",
    "    print(f\"precision : {prec:.3f}\")\n",
    "    print(f\"recall    : {rec:.3f}\")\n",
    "    print(f\"mean IoU  : {miou:.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-venv)",
   "language": "python",
   "name": "tf-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
